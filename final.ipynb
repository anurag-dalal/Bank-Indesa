{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b6132e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages...\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cbada85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data...\n",
    "df_train = pd.read_csv('ML_Artivatic_dataset\\\\train_indessa.csv')\n",
    "df_test = pd.read_csv('ML_Artivatic_dataset\\\\test_indessa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "051b6f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Available Columns: 'member_id', 'loan_amnt', 'funded_amnt', 'addr_state', 'sub_grade', 'term', 'batch_enrolled', 'desc', 'grade', 'emp_length', 'int_rate', 'pymnt_plan', 'initial_list_status', 'home_ownership', 'annual_inc', 'verification_status', 'purpose', 'dti', 'delinq_2yrs', 'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'application_type', 'verification_status_joint', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', 'last_week_pay', 'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'total_rev_hi_lim', 'loan_status\n",
    "df_train = df_train[['member_id', 'loan_amnt', 'funded_amnt', 'addr_state', 'funded_amnt_inv', 'sub_grade', 'term', 'emp_length', 'int_rate', 'annual_inc', 'dti', 'delinq_2yrs', 'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', 'last_week_pay', 'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'total_rev_hi_lim', 'loan_status']]\n",
    "df_test = df_test[['member_id', 'loan_amnt', 'funded_amnt', 'addr_state', 'funded_amnt_inv', 'sub_grade', 'term', 'emp_length', 'int_rate', 'annual_inc', 'dti', 'delinq_2yrs', 'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', 'last_week_pay', 'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'total_rev_hi_lim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7324a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform: term...\n",
      "Transform: emp_length...\n",
      "Transform: last_week_pay...\n",
      "Transform: sub_grade...\n",
      "Transform done.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Data transformation/cleanup\n",
    "Strip off textual parts, represent values as numeric values\n",
    "it makes sense. Convert the datatype to numeric.\n",
    "'''\n",
    "\n",
    "print('Transform: term...')\n",
    "df_train['term'].replace(to_replace=' months', value='', regex=True, inplace=True)\n",
    "df_test['term'].replace(to_replace=' months', value='', regex=True, inplace=True)\n",
    "df_train['term'] = pd.to_numeric(df_train['term'], errors='coerce')\n",
    "df_test['term'] = pd.to_numeric(df_test['term'], errors='coerce')\n",
    "\n",
    "print('Transform: emp_length...')\n",
    "df_train['emp_length'].replace('n/a', '0', inplace=True)\n",
    "df_train['emp_length'].replace(to_replace='\\+ years', value='', regex=True, inplace=True)\n",
    "df_train['emp_length'].replace(to_replace=' years', value='', regex=True, inplace=True)\n",
    "df_train['emp_length'].replace(to_replace='< 1 year', value='0', regex=True, inplace=True)\n",
    "df_train['emp_length'].replace(to_replace=' year', value='', regex=True, inplace=True)\n",
    "df_test['emp_length'].replace('n/a', '0', inplace=True)\n",
    "df_test['emp_length'].replace(to_replace='\\+ years', value='', regex=True, inplace=True)\n",
    "df_test['emp_length'].replace(to_replace=' years', value='', regex=True, inplace=True)\n",
    "df_test['emp_length'].replace(to_replace='< 1 year', value='0', regex=True, inplace=True)\n",
    "df_test['emp_length'].replace(to_replace=' year', value='', regex=True, inplace=True)\n",
    "df_train['emp_length'] = pd.to_numeric(df_train['emp_length'], errors='coerce')\n",
    "df_test['emp_length'] = pd.to_numeric(df_test['emp_length'], errors='coerce')\n",
    "\n",
    "print('Transform: last_week_pay...')\n",
    "df_train['last_week_pay'].replace(to_replace='th week', value='', regex=True, inplace=True)\n",
    "df_test['last_week_pay'].replace(to_replace='th week', value='', regex=True, inplace=True)\n",
    "df_train['last_week_pay'].replace(to_replace='NA', value='', regex=True, inplace=True)\n",
    "df_test['last_week_pay'].replace(to_replace='NA', value='', regex=True, inplace=True)\n",
    "df_train['last_week_pay'] = pd.to_numeric(df_train['last_week_pay'], errors='coerce')\n",
    "df_test['last_week_pay'] = pd.to_numeric(df_test['last_week_pay'], errors='coerce')\n",
    "\n",
    "print('Transform: sub_grade...')\n",
    "df_train['sub_grade'].replace(to_replace='A', value='0', regex=True, inplace=True)\n",
    "df_train['sub_grade'].replace(to_replace='B', value='1', regex=True, inplace=True)\n",
    "df_train['sub_grade'].replace(to_replace='C', value='2', regex=True, inplace=True)\n",
    "df_train['sub_grade'].replace(to_replace='D', value='3', regex=True, inplace=True)\n",
    "df_train['sub_grade'].replace(to_replace='E', value='4', regex=True, inplace=True)\n",
    "df_train['sub_grade'].replace(to_replace='F', value='5', regex=True, inplace=True)\n",
    "df_train['sub_grade'].replace(to_replace='G', value='6', regex=True, inplace=True)\n",
    "df_test['sub_grade'].replace(to_replace='A', value='0', regex=True, inplace=True)\n",
    "df_test['sub_grade'].replace(to_replace='B', value='1', regex=True, inplace=True)\n",
    "df_test['sub_grade'].replace(to_replace='C', value='2', regex=True, inplace=True)\n",
    "df_test['sub_grade'].replace(to_replace='D', value='3', regex=True, inplace=True)\n",
    "df_test['sub_grade'].replace(to_replace='E', value='4', regex=True, inplace=True)\n",
    "df_test['sub_grade'].replace(to_replace='F', value='5', regex=True, inplace=True)\n",
    "df_test['sub_grade'].replace(to_replace='G', value='6', regex=True, inplace=True)\n",
    "df_train['sub_grade'] = pd.to_numeric(df_train['sub_grade'], errors='coerce')\n",
    "df_test['sub_grade'] = pd.to_numeric(df_test['sub_grade'], errors='coerce')\n",
    "\n",
    "print('Transform done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7857fd9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation with Median: term\n",
      "Imputation with Median: loan_amnt\n",
      "Imputation with Median: funded_amnt\n",
      "Imputation with Median: last_week_pay\n",
      "Imputation with Median: int_rate\n",
      "Imputation with Median: sub_grade\n",
      "Imputation with Median: annual_inc\n",
      "Imputation with Median: dti\n",
      "Imputation with Median: mths_since_last_delinq\n",
      "Imputation with Median: mths_since_last_record\n",
      "Imputation with Median: open_acc\n",
      "Imputation with Median: revol_bal\n",
      "Imputation with Median: revol_util\n",
      "Imputation with Median: total_acc\n",
      "Imputation with Median: total_rec_int\n",
      "Imputation with Median: mths_since_last_major_derog\n",
      "Imputation with Median: tot_coll_amt\n",
      "Imputation with Median: tot_cur_bal\n",
      "Imputation with Median: total_rev_hi_lim\n",
      "Imputation with Median: emp_length\n",
      "Imputation with Zero: acc_now_delinq\n",
      "Imputation with Zero: total_rec_late_fee\n",
      "Imputation with Zero: recoveries\n",
      "Imputation with Zero: collection_recovery_fee\n",
      "Imputation with Zero: collections_12_mths_ex_med\n",
      "Missing value imputation done.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Missing values imputation\n",
    "'''\n",
    "cols = ['term', 'loan_amnt', 'funded_amnt', 'last_week_pay', 'int_rate', 'sub_grade', 'annual_inc', 'dti', 'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'revol_bal', 'revol_util', 'total_acc', 'total_rec_int', 'mths_since_last_major_derog', 'tot_coll_amt', 'tot_cur_bal', 'total_rev_hi_lim', 'emp_length']\n",
    "for col in cols:\n",
    "    print('Imputation with Median: %s' % (col))\n",
    "    df_train[col].fillna(df_train[col].median(), inplace=True)\n",
    "    df_test[col].fillna(df_test[col].median(), inplace=True)\n",
    "\n",
    "cols = ['acc_now_delinq', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'collections_12_mths_ex_med']\n",
    "for col in cols:\n",
    "    print('Imputation with Zero: %s' % (col))\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)\n",
    "\n",
    "print('Missing value imputation done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66efab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Feature Engineering\n",
    "'''\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "# Separating the member_id column of test dataframe to help create a csv after predictions\n",
    "test_member_id = pd.DataFrame(df_test['member_id'])\n",
    "\n",
    "\n",
    "# Creating target variable pandas series from train dataframe, this will be used by cross validation to calculate\n",
    "# the accuracy of the model\n",
    "train_target = pd.DataFrame(df_train['loan_status'])\n",
    "\n",
    "\n",
    "# It's good to create a copy of train and test dataframes. this way we can play around different features as we tune the\n",
    "# performance of the classifier with important features\n",
    "selected_cols = ['member_id', 'emp_length', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'sub_grade', 'int_rate', 'annual_inc', 'dti', 'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'revol_bal', 'revol_util', 'total_acc', 'total_rec_int', 'total_rec_late_fee', 'mths_since_last_major_derog', 'last_week_pay', 'tot_cur_bal', 'total_rev_hi_lim', 'tot_coll_amt', 'recoveries', 'collection_recovery_fee', 'term', 'acc_now_delinq', 'collections_12_mths_ex_med']\n",
    "final_train = df_train[selected_cols]\n",
    "final_test = df_test[selected_cols]\n",
    "\n",
    "# How big the loan a person has taken with respect to his earnings, annual income to loan amount ratio\n",
    "final_train['loan_to_income'] = final_train['annual_inc']/final_train['funded_amnt']\n",
    "final_test['loan_to_income'] = final_test['annual_inc']/final_test['funded_amnt']\n",
    "\n",
    "\n",
    "# All these attributes indicate that the repayment was not all hunky-dory. All the amounts caclulated are ratios \n",
    "# like, recovery to the loan amount. This column gives a magnitude of how much the repayment has gone off course \n",
    "# in terms of ratios.\n",
    "final_train['bad_state'] = final_train['acc_now_delinq'] + (final_train['total_rec_late_fee']/final_train['funded_amnt']) + (final_train['recoveries']/final_train['funded_amnt']) + (final_train['collection_recovery_fee']/final_train['funded_amnt_inv']) + (final_train['collections_12_mths_ex_med']/final_train['funded_amnt_inv'])\n",
    "final_test['bad_state'] = final_test['acc_now_delinq'] + (final_test['total_rec_late_fee']/final_test['funded_amnt']) + (final_test['recoveries']/final_test['funded_amnt']) + (final_test['collection_recovery_fee']/final_test['funded_amnt_inv']) + (final_train['collections_12_mths_ex_med']/final_test['funded_amnt_inv'])\n",
    "\n",
    "# For the sake of this model, I have used just a boolean flag if things had gone bad, with this case I didn't see\n",
    "# a benifit of including above computations\n",
    "final_train.loc[final_train['bad_state'] > 0, 'bad_state'] = 1\n",
    "final_test.loc[final_test['bad_state'] > 0, 'bad_state'] = 1\n",
    "\n",
    "\n",
    "# Total number of available/unused 'credit lines'\n",
    "final_train['avl_lines'] = final_train['total_acc'] - final_train['open_acc']\n",
    "final_test['avl_lines'] = final_test['total_acc'] - final_test['open_acc']\n",
    "\n",
    "\n",
    "# Interest paid so far\n",
    "final_train['int_paid'] = final_train['total_rec_int'] + final_train['total_rec_late_fee']\n",
    "final_test['int_paid'] = final_test['total_rec_int'] + final_test['total_rec_late_fee']\n",
    "\n",
    "\n",
    "# Calculating EMIs paid (in terms of percent)\n",
    "final_train['emi_paid_progress_perc'] = ((final_train['last_week_pay']/(final_train['term']/12*52+1))*100)\n",
    "final_test['emi_paid_progress_perc'] = ((final_test['last_week_pay']/(final_test['term']/12*52+1))*100)\n",
    "\n",
    "\n",
    "# Calculating total repayments received so far, in terms of EMI or recoveries after charge off\n",
    "final_train['total_repayment_progress'] = ((final_train['last_week_pay']/(final_train['term']/12*52+1))*100) + ((final_train['recoveries']/final_train['funded_amnt']) * 100)\n",
    "final_test['total_repayment_progress'] = ((final_test['last_week_pay']/(final_test['term']/12*52+1))*100) + ((final_test['recoveries']/final_test['funded_amnt']) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50ce13c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_id</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>...</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>term</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>loan_to_income</th>\n",
       "      <th>bad_state</th>\n",
       "      <th>avl_lines</th>\n",
       "      <th>int_paid</th>\n",
       "      <th>emi_paid_progress_perc</th>\n",
       "      <th>total_repayment_progress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58189336</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14350</td>\n",
       "      <td>14350</td>\n",
       "      <td>14350.0</td>\n",
       "      <td>43</td>\n",
       "      <td>19.19</td>\n",
       "      <td>28700.0</td>\n",
       "      <td>33.88</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1173.84</td>\n",
       "      <td>16.560510</td>\n",
       "      <td>16.560510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70011223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4800</td>\n",
       "      <td>4800</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>14</td>\n",
       "      <td>10.99</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>3.64</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.541667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>83.95</td>\n",
       "      <td>5.732484</td>\n",
       "      <td>5.732484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70255675</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7.26</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>18.42</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>56.47</td>\n",
       "      <td>5.732484</td>\n",
       "      <td>5.732484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1893936</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15000</td>\n",
       "      <td>15000</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>35</td>\n",
       "      <td>19.72</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>14.97</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4858.62</td>\n",
       "      <td>85.987261</td>\n",
       "      <td>85.987261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7652106</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>10.64</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>20.16</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2296.41</td>\n",
       "      <td>61.146497</td>\n",
       "      <td>61.146497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   member_id  emp_length  loan_amnt  funded_amnt  funded_amnt_inv  sub_grade  \\\n",
       "0   58189336         9.0      14350        14350          14350.0         43   \n",
       "1   70011223         0.0       4800         4800           4800.0         14   \n",
       "2   70255675         2.0      10000        10000          10000.0          4   \n",
       "3    1893936        10.0      15000        15000          15000.0         35   \n",
       "4    7652106        10.0      16000        16000          16000.0         12   \n",
       "\n",
       "   int_rate  annual_inc    dti  mths_since_last_delinq  ...  \\\n",
       "0     19.19     28700.0  33.88                    50.0  ...   \n",
       "1     10.99     65000.0   3.64                    31.0  ...   \n",
       "2      7.26     45000.0  18.42                    31.0  ...   \n",
       "3     19.72    105000.0  14.97                    46.0  ...   \n",
       "4     10.64     52000.0  20.16                    31.0  ...   \n",
       "\n",
       "   collection_recovery_fee  term  acc_now_delinq  collections_12_mths_ex_med  \\\n",
       "0                      0.0    36             0.0                         0.0   \n",
       "1                      0.0    36             0.0                         0.0   \n",
       "2                      0.0    36             0.0                         0.0   \n",
       "3                      0.0    36             0.0                         0.0   \n",
       "4                      0.0    36             0.0                         0.0   \n",
       "\n",
       "   loan_to_income  bad_state  avl_lines  int_paid  emi_paid_progress_perc  \\\n",
       "0        2.000000        0.0       14.0   1173.84               16.560510   \n",
       "1       13.541667        0.0        7.0     83.95                5.732484   \n",
       "2        4.500000        0.0       14.0     56.47                5.732484   \n",
       "3        7.000000        0.0       11.0   4858.62               85.987261   \n",
       "4        3.250000        0.0       16.0   2296.41               61.146497   \n",
       "\n",
       "   total_repayment_progress  \n",
       "0                 16.560510  \n",
       "1                  5.732484  \n",
       "2                  5.732484  \n",
       "3                 85.987261  \n",
       "4                 61.146497  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b662f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Split data set into train-test-cv\n",
    "Train model & predict\n",
    "'''\n",
    "# Split train and cross validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(final_train), np.array(train_target), test_size=0.30)\n",
    "eval_set=[(X_test, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74eb5341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anu\\anaconda3\\envs\\ML2\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Anu\\anaconda3\\envs\\ML2\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:16:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 32 minutes and 53.59 seconds.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.5, gamma=10, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.15, max_delta_step=0, max_depth=20,\n",
      "              min_child_weight=7, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=700, n_jobs=12, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "{'n_estimators': 700, 'min_child_weight': 7, 'max_depth': 20, 'learning_rate': 0.15, 'gamma': 10, 'colsample_bytree': 0.5}\n"
     ]
    }
   ],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "params={\n",
    " \"learning_rate\"    : [0.05, 0.10, 0.15] ,\n",
    " \"max_depth\"        : [3, 10, 15, 20],\n",
    " \"min_child_weight\" : [1, 3, 5, 7 ],\n",
    " \"gamma\"            : [0.1, 0.5, 1, 10, 20 ],\n",
    " \"colsample_bytree\" : [0.3, 0.4, 0.5 , 0.7 ],\n",
    " \"n_estimators\"     : [100, 500, 700]\n",
    "}\n",
    "\n",
    "## Hyperparameter optimization using RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "        \n",
    "classifier=xgboost.sklearn.XGBClassifier()\n",
    "random_search=RandomizedSearchCV(classifier,param_distributions=params,n_iter=5,scoring='roc_auc',n_jobs=-1,cv=5,verbose=3)\n",
    "from datetime import datetime\n",
    "# Here we go\n",
    "start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "random_search.fit(X_train,y_train)\n",
    "timer(start_time) # timing ends here for \"start_time\" variable\n",
    "\n",
    "print(random_search.best_estimator_)\n",
    "print(random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0255c9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing xgboost.sklearn.XGBClassifier and starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anu\\anaconda3\\envs\\ML2\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Anu\\anaconda3\\envs\\ML2\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.96549\n",
      "[1]\tvalidation_0-auc:0.96269\n",
      "[2]\tvalidation_0-auc:0.95830\n",
      "[3]\tvalidation_0-auc:0.95979\n",
      "[4]\tvalidation_0-auc:0.96059\n",
      "[5]\tvalidation_0-auc:0.95990\n",
      "[6]\tvalidation_0-auc:0.95905\n",
      "[7]\tvalidation_0-auc:0.96732\n",
      "[8]\tvalidation_0-auc:0.96768\n",
      "[9]\tvalidation_0-auc:0.96759\n",
      "[10]\tvalidation_0-auc:0.96966\n",
      "[11]\tvalidation_0-auc:0.96949\n",
      "[12]\tvalidation_0-auc:0.97085\n",
      "[13]\tvalidation_0-auc:0.97165\n",
      "[14]\tvalidation_0-auc:0.97130\n",
      "[15]\tvalidation_0-auc:0.97201\n",
      "[16]\tvalidation_0-auc:0.97207\n",
      "[17]\tvalidation_0-auc:0.97212\n",
      "[18]\tvalidation_0-auc:0.97225\n",
      "[19]\tvalidation_0-auc:0.97291\n",
      "[20]\tvalidation_0-auc:0.97293\n",
      "[21]\tvalidation_0-auc:0.97349\n",
      "[22]\tvalidation_0-auc:0.97356\n",
      "[23]\tvalidation_0-auc:0.97364\n",
      "[24]\tvalidation_0-auc:0.97357\n",
      "[25]\tvalidation_0-auc:0.97362\n",
      "[26]\tvalidation_0-auc:0.97359\n",
      "[27]\tvalidation_0-auc:0.97358\n",
      "[28]\tvalidation_0-auc:0.97405\n",
      "[29]\tvalidation_0-auc:0.97455\n",
      "[30]\tvalidation_0-auc:0.97479\n",
      "[31]\tvalidation_0-auc:0.97476\n",
      "[32]\tvalidation_0-auc:0.97486\n",
      "[33]\tvalidation_0-auc:0.97519\n",
      "[34]\tvalidation_0-auc:0.97521\n",
      "[35]\tvalidation_0-auc:0.97525\n",
      "[36]\tvalidation_0-auc:0.97526\n",
      "[37]\tvalidation_0-auc:0.97546\n",
      "[38]\tvalidation_0-auc:0.97543\n",
      "[39]\tvalidation_0-auc:0.97542\n",
      "[40]\tvalidation_0-auc:0.97542\n",
      "[41]\tvalidation_0-auc:0.97565\n",
      "[42]\tvalidation_0-auc:0.97570\n",
      "[43]\tvalidation_0-auc:0.97570\n",
      "[44]\tvalidation_0-auc:0.97577\n",
      "[45]\tvalidation_0-auc:0.97581\n",
      "[46]\tvalidation_0-auc:0.97582\n",
      "[47]\tvalidation_0-auc:0.97581\n",
      "[48]\tvalidation_0-auc:0.97586\n",
      "[49]\tvalidation_0-auc:0.97595\n",
      "[50]\tvalidation_0-auc:0.97591\n",
      "[51]\tvalidation_0-auc:0.97592\n",
      "[52]\tvalidation_0-auc:0.97596\n",
      "[53]\tvalidation_0-auc:0.97593\n",
      "[54]\tvalidation_0-auc:0.97596\n",
      "[55]\tvalidation_0-auc:0.97593\n",
      "[56]\tvalidation_0-auc:0.97597\n",
      "[57]\tvalidation_0-auc:0.97597\n",
      "[58]\tvalidation_0-auc:0.97598\n",
      "[59]\tvalidation_0-auc:0.97600\n",
      "[60]\tvalidation_0-auc:0.97603\n",
      "[61]\tvalidation_0-auc:0.97606\n",
      "[62]\tvalidation_0-auc:0.97608\n",
      "[63]\tvalidation_0-auc:0.97605\n",
      "[64]\tvalidation_0-auc:0.97607\n",
      "[65]\tvalidation_0-auc:0.97611\n",
      "[66]\tvalidation_0-auc:0.97610\n",
      "[67]\tvalidation_0-auc:0.97611\n",
      "[68]\tvalidation_0-auc:0.97617\n",
      "[69]\tvalidation_0-auc:0.97616\n",
      "[70]\tvalidation_0-auc:0.97619\n",
      "[71]\tvalidation_0-auc:0.97617\n",
      "[72]\tvalidation_0-auc:0.97617\n",
      "[73]\tvalidation_0-auc:0.97617\n",
      "[74]\tvalidation_0-auc:0.97616\n",
      "[75]\tvalidation_0-auc:0.97617\n",
      "[76]\tvalidation_0-auc:0.97624\n",
      "[77]\tvalidation_0-auc:0.97626\n",
      "[78]\tvalidation_0-auc:0.97626\n",
      "[79]\tvalidation_0-auc:0.97624\n",
      "[80]\tvalidation_0-auc:0.97623\n",
      "[81]\tvalidation_0-auc:0.97617\n",
      "[82]\tvalidation_0-auc:0.97618\n",
      "[83]\tvalidation_0-auc:0.97620\n",
      "[84]\tvalidation_0-auc:0.97617\n",
      "[85]\tvalidation_0-auc:0.97619\n",
      "[86]\tvalidation_0-auc:0.97615\n",
      "[87]\tvalidation_0-auc:0.97619\n",
      "[88]\tvalidation_0-auc:0.97618\n",
      "[89]\tvalidation_0-auc:0.97617\n",
      "[90]\tvalidation_0-auc:0.97617\n",
      "[91]\tvalidation_0-auc:0.97618\n",
      "[92]\tvalidation_0-auc:0.97617\n",
      "[93]\tvalidation_0-auc:0.97618\n",
      "[94]\tvalidation_0-auc:0.97613\n",
      "[95]\tvalidation_0-auc:0.97614\n",
      "[96]\tvalidation_0-auc:0.97614\n",
      "0:00:50.751999\n",
      "Accuracy: 94.1331880873%\n",
      "ROC-AUC: 92.4865812572%\n",
      "[0.0792198  0.00384167 0.00506813 0.00699167 0.0113809  0.0164856\n",
      " 0.01134078 0.00500385 0.00901736 0.00402246 0.00419717 0.00362036\n",
      " 0.00385268 0.0049125  0.00311883 0.01286034 0.00729418 0.00315385\n",
      " 0.06928269 0.01316292 0.03242226 0.00492622 0.19626325 0.09623226\n",
      " 0.07642577 0.03040546 0.01600646 0.00629967 0.17514546 0.00647859\n",
      " 0.01015786 0.0338959  0.03751299]\n",
      "0 member_id\n",
      "1 emp_length\n",
      "2 loan_amnt\n",
      "3 funded_amnt\n",
      "4 funded_amnt_inv\n",
      "5 sub_grade\n",
      "6 int_rate\n",
      "7 annual_inc\n",
      "8 dti\n",
      "9 mths_since_last_delinq\n",
      "10 mths_since_last_record\n",
      "11 open_acc\n",
      "12 revol_bal\n",
      "13 revol_util\n",
      "14 total_acc\n",
      "15 total_rec_int\n",
      "16 total_rec_late_fee\n",
      "17 mths_since_last_major_derog\n",
      "18 last_week_pay\n",
      "19 tot_cur_bal\n",
      "20 total_rev_hi_lim\n",
      "21 tot_coll_amt\n",
      "22 recoveries\n",
      "23 collection_recovery_fee\n",
      "24 term\n",
      "25 acc_now_delinq\n",
      "26 collections_12_mths_ex_med\n",
      "27 loan_to_income\n",
      "28 bad_state\n",
      "29 avl_lines\n",
      "30 int_paid\n",
      "31 emi_paid_progress_perc\n",
      "32 total_repayment_progress\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Initializing xgboost.sklearn.XGBClassifier and starting training...')\n",
    "\n",
    "st = datetime.now()\n",
    "\n",
    "clf = xgboost.sklearn.XGBClassifier(\n",
    "    objective=\"binary:logistic\", \n",
    "    learning_rate=0.15, \n",
    "    seed=9616, \n",
    "    max_depth=20, \n",
    "    gamma=10,\n",
    "    min_child_weight=7,\n",
    "    colsample_bytree=0.5,\n",
    "    n_estimators=700)\n",
    "\n",
    "clf.fit(X_train, y_train, early_stopping_rounds=20, eval_metric=\"auc\", eval_set=eval_set, verbose=True)\n",
    "\n",
    "print(datetime.now()-st)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "submission_file_name = 'Submission_'\n",
    "\n",
    "accuracy = accuracy_score(np.array(y_test).flatten(), y_pred)\n",
    "print(\"Accuracy: %.10f%%\" % (accuracy * 100.0))\n",
    "submission_file_name = submission_file_name + (\"_Accuracy_%.6f\" % (accuracy * 100)) + '_'\n",
    "\n",
    "accuracy_per_roc_auc = roc_auc_score(np.array(y_test).flatten(), y_pred)\n",
    "print(\"ROC-AUC: %.10f%%\" % (accuracy_per_roc_auc * 100))\n",
    "submission_file_name = submission_file_name + (\"_ROC-AUC_%.6f\" % (accuracy_per_roc_auc * 100))\n",
    "\n",
    "final_pred = pd.DataFrame(clf.predict_proba(np.array(final_test)))\n",
    "dfSub = pd.concat([test_member_id, final_pred.iloc[:, 1:2]], axis=1)\n",
    "dfSub.rename(columns={1:'loan_status'}, inplace=True)\n",
    "dfSub.to_csv((('%s.csv') % (submission_file_name)), index=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(clf.feature_importances_)\n",
    "idx = 0\n",
    "for x in list(final_train):\n",
    "    print('%d %s' % (idx, x))\n",
    "    idx = idx + 1\n",
    "plt.bar(range(len(clf.feature_importances_)), clf.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9f3c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
